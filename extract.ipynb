{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List, Optional, Union, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url: str) -> BeautifulSoup:\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "def clean_box_office(box_office_str: str) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Clean box office string and convert to float.\n",
    "    \n",
    "    Args:\n",
    "        box_office_str: String containing box office value\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned box office value as float or None if conversion fails\n",
    "    \"\"\"\n",
    "    if '$' in box_office_str:\n",
    "        box_office_str = box_office_str[box_office_str.find('$'):]\n",
    "    \n",
    "    clean_str = re.sub(r'[^\\d.]', '', box_office_str)\n",
    "    try:\n",
    "        return float(clean_str) if clean_str else None\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_from_text(text: str) -> Optional[int]:\n",
    "    year_match = re.search(r'\\((\\d{4})\\)', text)\n",
    "    if year_match:\n",
    "        return int(year_match.group(1))\n",
    "    \n",
    "    year_match = re.search(r'\\b(19\\d{2}|20\\d{2})\\b', text)\n",
    "    return int(year_match.group(1)) if year_match else None\n",
    "\n",
    "def get_film_details(film_url: str) -> Dict[str, Any]:\n",
    "    details = {\n",
    "        'director': 'Unknown',\n",
    "        'country': 'Unknown'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        film_soup = get_soup(f\"https://en.wikipedia.org{film_url}\")\n",
    "        \n",
    "        infobox = film_soup.find('table', class_='infobox')\n",
    "        if infobox:\n",
    "            director_row = infobox.find('th', string=re.compile(r'Direct(ed by|or)'))\n",
    "            if director_row:\n",
    "                director_cell = director_row.find_next('td')\n",
    "                if director_cell:\n",
    "                    directors = [d.strip() for d in director_cell.text.strip().split('\\n')]\n",
    "                    details['director'] = ', '.join(directors)\n",
    "            \n",
    "            country_row = infobox.find('th', string=re.compile(r'Countr(y|ies)'))\n",
    "            if country_row:\n",
    "                country_cell = country_row.find_next('td')\n",
    "                if country_cell:\n",
    "                    country_list = country_cell.find('ul')\n",
    "                    if country_list:\n",
    "                        first_country_item = country_list.find('li')\n",
    "                        if first_country_item:\n",
    "                            country_text = re.sub(r'\\[\\d+\\]', '', first_country_item.get_text())\n",
    "                            details['country'] = country_text.strip()\n",
    "                    else:\n",
    "                        for br in country_cell.find_all('br'):\n",
    "                            br.replace_with('\\n')\n",
    "                        \n",
    "                        country_text = country_cell.get_text()\n",
    "                        country_text = re.sub(r'\\[\\d+\\]', '', country_text)\n",
    "                        countries = re.split(r'[,\\n]', country_text)\n",
    "                        first_country = countries[0].strip() if countries else 'Unknown'\n",
    "                        details['country'] = first_country\n",
    "        \n",
    "        if details['director'] == 'Unknown':\n",
    "            first_para = film_soup.find('div', class_='mw-parser-output').find('p')\n",
    "            if first_para:\n",
    "                director_match = re.search(r'directed by ([^.]+)', first_para.text)\n",
    "                if director_match:\n",
    "                    details['director'] = director_match.group(1).strip()\n",
    "        \n",
    "        if details['country'] == 'Unknown':\n",
    "            first_para = film_soup.find('div', class_='mw-parser-output').find('p')\n",
    "            if first_para:\n",
    "                country_match = re.search(r'(?:is a|a \\d{4})(?: [^.]+?)? ([^.]+?) (?:film|movie)', first_para.text)\n",
    "                if country_match:\n",
    "                    country_text = country_match.group(1).strip()\n",
    "                    country_text = re.sub(r'\\[\\d+\\]', '', country_text)\n",
    "                    countries = re.split(r'[,\\n]', country_text)\n",
    "                    first_country = countries[0].strip() if countries else 'Unknown'\n",
    "                    details['country'] = first_country\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting details from {film_url}: {e}\")\n",
    "    \n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
    "soup = get_soup(url)\n",
    "\n",
    "tables = soup.find_all('table', class_='wikitable')\n",
    "main_table = None\n",
    "\n",
    "for table in tables:\n",
    "    headers = [th.text.strip() for th in table.find_all('th')]\n",
    "    if 'Rank' in headers and 'Title' in headers and 'Worldwide gross' in headers:\n",
    "        main_table = table\n",
    "        break\n",
    "\n",
    "if not main_table:\n",
    "    print(\"Could not find the main table with film data\")\n",
    "    return\n",
    "\n",
    "films_data = []\n",
    "\n",
    "for row in main_table.find_all('tr')[1:]:\n",
    "    cells = row.find_all(['td', 'th'])\n",
    "    if len(cells) >= 4:\n",
    "        try:\n",
    "            rank = cells[0].text.strip()\n",
    "            if not rank.isdigit():\n",
    "                continue\n",
    "            \n",
    "            title_cell = cells[2]\n",
    "            title_link = title_cell.find('a')\n",
    "            \n",
    "            if not title_link:\n",
    "                continue\n",
    "            \n",
    "            title = title_link.text.strip()\n",
    "            film_url = title_link.get('href')\n",
    "            \n",
    "            box_office_cell = cells[3]\n",
    "            box_office_str = box_office_cell.text.strip()\n",
    "            box_office = clean_box_office(box_office_str)\n",
    "            \n",
    "            year_cell = cells[4] if len(cells) > 4 else None\n",
    "            year = int(year_cell.text.strip()) if year_cell and year_cell.text.strip().isdigit() else None\n",
    "            \n",
    "            if not year:\n",
    "                year = extract_year_from_text(title)\n",
    "            \n",
    "            print(f\"Fetching details for {title}...\")\n",
    "            film_details = get_film_details(film_url)\n",
    "            \n",
    "            films_data.append({\n",
    "                'title': title,\n",
    "                'release_year': year,\n",
    "                'director': film_details['director'],\n",
    "                'box_office': box_office,\n",
    "                'country': film_details['country']\n",
    "            })\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {e}\")\n",
    "\n",
    "conn = sqlite3.connect('highest_grossing_films.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS films (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT NOT NULL,\n",
    "    release_year INTEGER,\n",
    "    director TEXT,\n",
    "    box_office REAL,\n",
    "    country TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "cursor.execute('DELETE FROM films')\n",
    "\n",
    "for film in films_data:\n",
    "    cursor.execute('''\n",
    "    INSERT INTO films (title, release_year, director, box_office, country)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        film['title'],\n",
    "        film['release_year'],\n",
    "        film['director'],\n",
    "        film['box_office'],\n",
    "        film['country']\n",
    "    ))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "with open('films_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(films_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Successfully extracted data for {len(films_data)} films\")\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
